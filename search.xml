<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>HDFS分布式文件系统</title>
      <link href="/2020/09/21/hdfs-fen-bu-shi-wen-jian-xi-tong/"/>
      <url>/2020/09/21/hdfs-fen-bu-shi-wen-jian-xi-tong/</url>
      
        <content type="html"><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>HDFS （Hadoop Distributed File System）是 Hadoop 下的分布式文件系统，具有高容错、高吞吐量等特性，可以部署在低成本的硬件上。</p><h2 id="HDFS-架构设计及原理"><a href="#HDFS-架构设计及原理" class="headerlink" title="HDFS 架构设计及原理"></a>HDFS 架构设计及原理</h2><h3 id="HDFS-架构"><a href="#HDFS-架构" class="headerlink" title="HDFS 架构"></a>HDFS 架构</h3><p>HDFS 遵循主/从架构，由单个 NameNode(NN) 和多个 DataNode(DN) 组成：</p><ul><li>NameNode : 负责执行有关 文件系统命名空间 的操作，例如打开，关闭、重命名文件和目录等。它同时还负责集群元数据的存储，记录着文件中各个数据块的位置信息。</li><li>DataNode：负责提供来自文件系统客户端的读写请求，执行块的创建，删除等操作。<br>NameNode节点分为 Active NameNode 和 Standby NameNode(作为主备切换)</li></ul><h3 id="文件系统命名空间"><a href="#文件系统命名空间" class="headerlink" title="文件系统命名空间"></a>文件系统命名空间</h3><p>HDFS的<strong>文件系统命名空间</strong>的层次结构与大多数文件系统类似 (如 Linux)， 支持目录和文件的创建、移动、删除和重命名等操作，支持配置用户和访问权限，但不支持硬链接和软连接。NameNode 负责维护文件系统名称空间，记录对名称空间或其属性的任何更改。</p><h3 id="数据复制"><a href="#数据复制" class="headerlink" title="数据复制"></a>数据复制</h3><p>为了保证数据的可靠性和容错性,提供了数据复制的机制.HDFS将存储的文件分成一系列的块,每个块由多个副本来保证容错性,默认配置下,每块为128M,复制因子为3(复制3份)。</p><h3 id="数据复制的实现原理"><a href="#数据复制的实现原理" class="headerlink" title="数据复制的实现原理"></a>数据复制的实现原理</h3><p>HDFS 采用机架感知副本放置策略，对于常见情况，当复制因子为 3 时，HDFS 的放置策略是：<br>在写入程序位于<strong>datanode</strong>上时，就优先将写入文件的一个副本放置在该<strong>datanode</strong>上，否则放在随机<strong>datanode</strong>上。之后在另一个远程机架上的任意一个节点上放置另一个副本，并在该机架上的另一个节点上放置最后一个副本。此策略可以减少机架间的写入流量，从而提高写入性能。<br>如果复制因子大于 3，则随机确定第 4 个和之后副本的放置位置，同时保持每个机架的副本数量低于上限，上限值通常为 （复制系数 - 1）/ 机架数量 + 2，需要注意的是不允许同一个<strong>datanode</strong>上具有同一个块的多个副本。</p><h3 id="副本的选择机制"><a href="#副本的选择机制" class="headerlink" title="副本的选择机制"></a>副本的选择机制</h3><p>为了最大限度地减少带宽消耗和读取延迟，HDFS 在执行读取请求时，优先读取距离读取器<strong>最近</strong>的副本。如果在与读取器节点相同的机架上存在副本，则优先选择该副本。如果 HDFS 群集跨越多个数据中心，则优先选择<strong>本地数据中心</strong>上的副本。</p><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><p>为了保证稳定性,每个DataNode会定期向NameNode发送心跳,如果超出了指定时间,则就会将这个DataNode标记为死亡状态,不可用了,那么就会导致数据也不可用了,NameNode就会跟踪这些数据块,在必要的时候进行重写复制。<br>数据完整性:如果数据遭到某些原因的损坏,而造成的读取错误,该怎么解决了?<br>    当客户端创建 HDFS 文件时,它会计算文件的每个块的 校验和,并将 校验和 存储在同一 HDFS 命名空间下的单独的隐藏文件中。当客户端检索文件内容时,它会验证从每个 DataNode 接收的数据是否与存储在关联校验和文件中的 校验和 匹配。如果匹配失败,则证明数据已经损坏,此时客户端会选择从其他 DataNode 获取该块的其他可用副本。<br>FsImage 和 EditLog:</p><ul><li>FsImage保存来最新的元数据检查点,包含来整个hdfs文件系统的所有目录和文件的信息。对于文件来说包括了数据块描述信息,修改时间,访问时间等,对于目录来说包括修改时间,访问权限控制信息（目录所属用户，所在组）等。Fimage就是在某一时刻,整个hdfs的快照,就是这个时刻的hdfs上所有的文件块和目录,分别的状态,位于哪些个datanode,各自的权限,各自的副本个数。</li><li>EditLog主要是在Namenode已经启动情况下对hdfs进行的各种更新操作进行记录，hdfs客户端执行所有的写操作都会被记录到editlog中。如果不断增大,就会先将hdfs的操作记录写入到一个新文件中,利用secondary namenode来将两者合拼成新的文件,然后再将这个文件的发回NameNode,重新命名。</li></ul><h2 id="写数据过程"><a href="#写数据过程" class="headerlink" title="写数据过程"></a>写数据过程</h2><p>先是客户端请求写入数据,将数据切成每个为128m的数据块,向NameNode请求,拷贝在3个地方,然后NameNode 就会寻找3个需要存放数据的地方,储存成功,向客户端回执,并将数据地址按照升序的方式发送给客户端,客户端开始写数据,将数据和列表发送给第一个DataNode(最近的),然后再第一个DataNode在接收的时候,同时向第二个发送数据和列表,第三个同样如此,完成之后,DataNode会向NameNode回执,表示发送完毕,所以数据发送完毕后,客户端就会请求关闭文件,NameNode会把元数据信息存储到硬盘上。</p><h2 id="读数据过程"><a href="#读数据过程" class="headerlink" title="读数据过程"></a>读数据过程</h2><p>客户端向NameNode请求读取数据(通过文件名),然后NameNode向客户端发送所有数据块的列表信息和每个块的DataNode的列表,然后客户端就会向DataNode发送请求下载数据文件。</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spring AOP</title>
      <link href="/2019/08/07/spring-aop/"/>
      <url>/2019/08/07/spring-aop/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spring IOC</title>
      <link href="/2019/08/07/spring-ioc/"/>
      <url>/2019/08/07/spring-ioc/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>大数据的学习方向</title>
      <link href="/2019/08/07/da-shu-ju-de-xue-xi-fang-xiang/"/>
      <url>/2019/08/07/da-shu-ju-de-xue-xi-fang-xiang/</url>
      
        <content type="html"><![CDATA[<h2 id="技能"><a href="#技能" class="headerlink" title="技能"></a>技能</h2><pre class=" language-yarn"><code class="language-yarn">基本开发语言 Java Scala PythonSQL能力结构化数据处理流式数据处理ETLKafka统计学分布式数据库</code></pre>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop </tag>
            
            <tag> Spark </tag>
            
            <tag> Scala </tag>
            
            <tag> Apache </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark的优化配置</title>
      <link href="/2019/08/07/spark-de-you-hua-pei-zhi/"/>
      <url>/2019/08/07/spark-de-you-hua-pei-zhi/</url>
      
        <content type="html"><![CDATA[<h2 id="优化配置"><a href="#优化配置" class="headerlink" title="优化配置"></a>优化配置</h2><pre class=" language-yarn"><code class="language-yarn">// TODO</code></pre>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark数据库的读取与写入</title>
      <link href="/2019/08/07/spark-shu-ju-ku-de-du-qu-yu-xie-ru/"/>
      <url>/2019/08/07/spark-shu-ju-ku-de-du-qu-yu-xie-ru/</url>
      
        <content type="html"><![CDATA[<h2 id="数据库的读取"><a href="#数据库的读取" class="headerlink" title="数据库的读取"></a>数据库的读取</h2><pre class=" language-scala"><code class="language-scala"><span class="token keyword">def</span> getDataFrame<span class="token punctuation">(</span>tableName<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token operator">:</span> DataFrame <span class="token operator">=</span> <span class="token punctuation">{</span>    <span class="token keyword">var</span> _spark<span class="token operator">:</span> SparkSession <span class="token operator">=</span> _    <span class="token keyword">val</span> spark<span class="token operator">=</span> _spark        <span class="token keyword">var</span> df<span class="token operator">=</span>spark<span class="token punctuation">.</span>read                <span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">"jdbc"</span><span class="token punctuation">)</span>                <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"driver"</span><span class="token punctuation">,</span> <span class="token string">"com.mysql.cj.jdbc.Driver"</span><span class="token punctuation">)</span>                <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"url"</span><span class="token punctuation">,</span> host<span class="token punctuation">)</span>                <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"dbtable"</span><span class="token punctuation">,</span> tableName<span class="token punctuation">)</span>                <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"user"</span><span class="token punctuation">,</span> user<span class="token punctuation">)</span>                <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"password"</span><span class="token punctuation">,</span> pwd<span class="token punctuation">)</span>                <span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></code></pre><hr><h2 id="数据库的写入"><a href="#数据库的写入" class="headerlink" title="数据库的写入"></a>数据库的写入</h2><pre class=" language-scala"><code class="language-scala"><span class="token keyword">def</span> output<span class="token punctuation">(</span>df<span class="token operator">:</span> DataFrame<span class="token punctuation">,</span> tableName<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> mode<span class="token operator">:</span> SaveMode<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>        df<span class="token punctuation">.</span>write                <span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">"jdbc"</span><span class="token punctuation">)</span>                <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"driver"</span><span class="token punctuation">,</span> <span class="token string">"com.mysql.cj.jdbc.Driver"</span><span class="token punctuation">)</span>                <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"url"</span><span class="token punctuation">,</span> SparkConfig<span class="token punctuation">.</span>host<span class="token punctuation">)</span>                <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"dbtable"</span><span class="token punctuation">,</span> tableName<span class="token punctuation">)</span>                <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"user"</span><span class="token punctuation">,</span> SparkConfig<span class="token punctuation">.</span>user<span class="token punctuation">)</span>                <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"password"</span><span class="token punctuation">,</span> SparkConfig<span class="token punctuation">.</span>pwd<span class="token punctuation">)</span>                <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"batchsize"</span><span class="token punctuation">,</span><span class="token number">50000</span><span class="token punctuation">)</span>                <span class="token punctuation">.</span>mode<span class="token punctuation">(</span>mode<span class="token punctuation">)</span>                <span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spark </tag>
            
            <tag> Scala </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java的学习笔记</title>
      <link href="/2019/08/07/java-de-xue-xi-bi-ji/"/>
      <url>/2019/08/07/java-de-xue-xi-bi-ji/</url>
      
        <content type="html"><![CDATA[<h2 id="学习书籍"><a href="#学习书籍" class="headerlink" title="学习书籍"></a>学习书籍</h2><p>// TODO</p><h2 id="项目"><a href="#项目" class="headerlink" title="项目"></a>项目</h2><p>// TODO</p><h2 id="知识栈"><a href="#知识栈" class="headerlink" title="知识栈"></a>知识栈</h2><p>// TODO</p><h2 id="习惯与思考"><a href="#习惯与思考" class="headerlink" title="习惯与思考"></a>习惯与思考</h2><p>// TODO</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
